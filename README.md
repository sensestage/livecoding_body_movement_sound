# livecoding_body_movement_sound
Repository for the workshop at the first ICLC


# Description

As (wireless) sensor interfaces become more and more available and accessible to artists, the creation of the the relationships between the data the sensors produce and the output in media has become more and more a subject of research. Rather than fixed relationships or mappings between sensor data and output media, livecoding can create a dialog between all the performers in an interactive performance, between the movement and the code, between the movers and the coders. Even in preparation of interactive performances, livecoding as a skill is very valuable in order to be able to quickly prototype different approaches of mapping data, try them out, and evaluate their artistic quality. The adaptations can range from changing of parameter ranges, to rewriting the algorithms that establish rules for mapping. As a mode of performance, this approach can enable a new form of improvisation, creating a dialog between dancers and livecoders, as the dancers adapt their movements based on the mappings to output media that are created by the livecoders, and the livecoders who adapt their code based on the movement of the dancers.

During the workshop we will collaboratively explore the livecoding of such mappings, using a wireless sensor system (the Sense/Stage MiniBee [1]), equipped with accelerometers and a selected range of other body-based sensors, and a data sharing network [2].

The workshop will start with an exploration of the framework within which we will work, before going on to exploring body movements, the sensor data this produces and strategies for mapping this data to output media - mainly sound. While examples of algorithms will be given in SuperCollider, for the experienced livecoder they should be easy to translate into his or her preferred programming language, as long as a quick access to incoming OSC data is available. The workshop should end with a collaborative livecoding and movement session of all participants.

[1] https://docs.sensestage.eu
[2] https://github.com/sensestage/xosc

# Requirements

## For participants:

* A laptop with the livecoding programming language that you are familiar with.
* The livecoding programming language should be capable of receiving (and sending) custom OSC messages.
* The laptop should have WiFi capabilities (or you should bring an ethernet cable).
* Participants with a background in movement (dance, theatre, etc) are also welcome - even if they may not be livecoders themselves, but are interested in the collaboration with livecoders.

## Required setup for the workshop:

* An open space to move.
* Tables and chairs for participants to sit and work on their laptops.
* One loudspeaker per participant (can be small monitors).
